__NR_io_uring_setup := 425
__NR_io_uring_enter := 426
__NR_io_uring_register := 427

IORING_FEAT_SINGLE_MMAP := 0
IORING_FEAT_NODROP := 1
IORING_FEAT_SUBMIT_STABLE := 2
IORING_FEAT_RW_CUR_POS := 4

IORING_OFF_SQ_RING := 0
IORING_OFF_CQ_RING := 0x8000000
IORING_OFF_SQES := 0x10000000

IORING_ENTER_GETEVENTS := 1

io_uring_sqe := class
{
	opcode := u8
	flags := u8
	ioprio := u16
	fd := s32
	off := u64 // also addr2
	addr := u64 
	len := u32
	command_flag := u32
	user_data := u64

	buf_index := u16 //also buf_group
	personality := u16
	splice_fd_in := u32 // also file_index

	pad1 := u64
	pad2 := u64
}

io_uring_cqe := class
{
	user_data := u64
	res := s32
	flags := u32
}

io_sqring_offsets := class
{
	head := u32
	tail := u32
	ring_mask := u32
	ring_entries := u32
	flags := u32
	dropped := u32
	array := u32
	resv1 := u32
	resv2 := u64
}
io_cqring_offsets := class
{
	head := u32
	tail := u32
	ring_mask := u32
	ring_entries := u32
	overflow := u32
	cqes := u32
	flags := u32
	resv1 := u32
	resv2 := u64
}
io_uring_params := class
{
	sq_entries := u32
	cq_entries := u32
	flags := u32
	sq_thread_cpu := u32
	sq_thread_idle := u32
	features := u32
	wq_fd := u32
	resv := u32[3]
	sq_off := io_sqring_offsets
	cq_off := io_cqring_offsets
}

io_uring_setup := !(u32 entries,io_uring_params^ p) -> int
{
	return syscall(__NR_io_uring_setup,entries,p)
}

io_uring_enter := !(int fd,int to_submit,int min_complete,int flags) -> int
{
	return syscall(__NR_io_uring_enter,fd,to_submit,min_complete,flags,null,0)
}

URing := class extend TGCObject
{
	ring_fd := int

	sq_head := u32^
	sq_tail := u32^

	cq_head := u32^
	cq_tail := u32^

	sq_array := u32^
	
	cqes := io_uring_cqe^
	sqes := io_uring_sqe^

	cqe_mask := u32
	sqe_mask := u32

	this := !() -> void
	{
		params := io_uring_params
		ring_fd = io_uring_setup(512,params&)

		assert(ring_fd > 0) //todo emit exception?

		sring_sz := params.sq_off.array + params.sq_entries*4
		cring_sz := params.cq_off.cqes + params.cq_entries*io_uring_cqe->TypeSize

		mp_ptr := mmap(null,cring_sz,PROT_READ + PROT_WRITE,MAP_SHARED + MAP_POPULATE,ring_fd,null)->{u8^}

		sq_array = mp_ptr[params.sq_off.array]&->{u32^}

		temp := s64
		temp = IORING_OFF_SQES
		sqes = mmap(null,params.sq_entries*io_uring_sqe->TypeSize,PROT_READ + PROT_WRITE,MAP_SHARED + MAP_POPULATE,ring_fd,temp&->{void^^}^)->{io_uring_sqe^}
		cqes = mp_ptr[params.cq_off.cqes]&->{io_uring_cqe^}

		sq_head = mp_ptr[params.sq_off.head]&->{u32^}
		sq_tail = mp_ptr[params.sq_off.tail]&->{u32^}

		cq_head = mp_ptr[params.cq_off.head]&->{u32^}
		cq_tail = mp_ptr[params.cq_off.tail]&->{u32^}

		cqe_mask = params.cq_off.ring_mask
		sqe_mask = params.sq_off.ring_mask
	}
	GetSQE := !() -> io_uring_sqe^
	{
		sIndex := sq_tail^
		MemBarrier()
		sq_array[sIndex] = sIndex

		sqe := sqes[sIndex]&
		ZeroMem(sqe^)

		MemBarrier()
		sIndex += 1
		sIndex = sIndex and_b sqe_mask
		sq_tail^ = sIndex
		return sqe
	}
	Submit := !() -> void
	{
		io_uring_enter(ring_fd,1,0,0)
	}
	WaitOne := !() -> io_uring_cqe^
	{
		if cq_head^ == sq_tail^
		{
			io_uring_enter(ring_fd,0,1,IORING_ENTER_GETEVENTS)
		}

		index := cq_head^
		result = cqes[index]&
		MemBarrier()
		index += 1
		index = index and_b cqe_mask
		MemBarrier()
		cq_head^ = index
	}
	Destroy := virtual !() -> void
	{
		close(ring_fd)
	}
}
